{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79dd2c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.514610Z",
     "start_time": "2022-02-15T03:32:29.579343Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91834085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf8322d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_cuda = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\") # defult setting\n",
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32fac8",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d06305",
   "metadata": {},
   "source": [
    "### Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f10f9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.752657Z",
     "start_time": "2022-02-15T03:32:32.515403Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "data = pd.read_csv('training.csv')\n",
    "item_feature = pd.read_csv('item_feature.csv')\n",
    "test = pd.read_csv('test_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40375aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.762472Z",
     "start_time": "2022-02-15T03:32:32.754352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970240</th>\n",
       "      <td>200152</td>\n",
       "      <td>30710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970241</th>\n",
       "      <td>200152</td>\n",
       "      <td>30710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970242</th>\n",
       "      <td>200152</td>\n",
       "      <td>12006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970243</th>\n",
       "      <td>200152</td>\n",
       "      <td>25030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970244</th>\n",
       "      <td>200152</td>\n",
       "      <td>14578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970245 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  context_feature_id\n",
       "0             0    28366                   2\n",
       "1             0    16109                   2\n",
       "2             0    11500                   3\n",
       "3             0    20750                   2\n",
       "4             0     8759                   2\n",
       "...         ...      ...                 ...\n",
       "970240   200152    30710                   2\n",
       "970241   200152    30710                   2\n",
       "970242   200152    12006                   2\n",
       "970243   200152    25030                   2\n",
       "970244   200152    14578                   2\n",
       "\n",
       "[970245 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e20f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.769292Z",
     "start_time": "2022-02-15T03:32:32.763350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22590</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381380</th>\n",
       "      <td>381380</td>\n",
       "      <td>200151</td>\n",
       "      <td>1702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381381</th>\n",
       "      <td>381381</td>\n",
       "      <td>200151</td>\n",
       "      <td>21632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381382</th>\n",
       "      <td>381382</td>\n",
       "      <td>200151</td>\n",
       "      <td>30477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381383</th>\n",
       "      <td>381383</td>\n",
       "      <td>200151</td>\n",
       "      <td>30477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381384</th>\n",
       "      <td>381384</td>\n",
       "      <td>200151</td>\n",
       "      <td>17715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381385 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  user_id  item_id  context_feature_id\n",
       "0            0        4    16835                   2\n",
       "1            1        4    22590                   3\n",
       "2            2        4     1978                   1\n",
       "3            3        4    28916                   1\n",
       "4            4        4    14427                   2\n",
       "...        ...      ...      ...                 ...\n",
       "381380  381380   200151     1702                   1\n",
       "381381  381381   200151    21632                   1\n",
       "381382  381382   200151    30477                   1\n",
       "381383  381383   200151    30477                   1\n",
       "381384  381384   200151    17715                   1\n",
       "\n",
       "[381385 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e78bf",
   "metadata": {},
   "source": [
    "### Check data duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bfad31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.850719Z",
     "start_time": "2022-02-15T03:32:32.770180Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete duplicate\n",
    "data = data[data.duplicated() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c9c2b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.857141Z",
     "start_time": "2022-02-15T03:32:32.851655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970239</th>\n",
       "      <td>200150</td>\n",
       "      <td>20387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970240</th>\n",
       "      <td>200152</td>\n",
       "      <td>30710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970242</th>\n",
       "      <td>200152</td>\n",
       "      <td>12006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970243</th>\n",
       "      <td>200152</td>\n",
       "      <td>25030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970244</th>\n",
       "      <td>200152</td>\n",
       "      <td>14578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892371 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  context_feature_id\n",
       "0             0    28366                   2\n",
       "1             0    16109                   2\n",
       "2             0    11500                   3\n",
       "3             0    20750                   2\n",
       "4             0     8759                   2\n",
       "...         ...      ...                 ...\n",
       "970239   200150    20387                   2\n",
       "970240   200152    30710                   2\n",
       "970242   200152    12006                   2\n",
       "970243   200152    25030                   2\n",
       "970244   200152    14578                   2\n",
       "\n",
       "[892371 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2833255",
   "metadata": {},
   "source": [
    "### Compare training and test data set coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a587eb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.879473Z",
     "start_time": "2022-02-15T03:32:32.858386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169698, 37893), (37978, 14586))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.user_id.nunique(), test.user_id.nunique()), (data.item_id.nunique(), test.item_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad9b0c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.885940Z",
     "start_time": "2022-02-15T03:32:32.880590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 200152), (0, 39900))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.user_id.min(), data.user_id.max()), (data.item_id.min(), data.item_id.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a594c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.891898Z",
     "start_time": "2022-02-15T03:32:32.888389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 200151), (3, 39899))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.user_id.min(), test.user_id.max()), (test.item_id.min(), test.item_id.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58987244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.928603Z",
     "start_time": "2022-02-15T03:32:32.892765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.628955216002954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test.user_id.unique()).intersection(set(data.user_id.unique()))) / len(set(test.user_id.unique())) * 100\n",
    "# 80% of test user_ids are new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8a3725d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:32.948560Z",
     "start_time": "2022-02-15T03:32:32.929589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.81612505141916"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test.item_id.unique()).intersection(set(data.item_id.unique()))) / len(set(test.item_id.unique())) * 100\n",
    "# 14% of test user_ids are new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84014b7c",
   "metadata": {},
   "source": [
    "As so many new user and item, we decided not to encode training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9ef88",
   "metadata": {},
   "source": [
    "### Are users unique in specific context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de81ee54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:33.072104Z",
     "start_time": "2022-02-15T03:32:32.949504Z"
    }
   },
   "outputs": [],
   "source": [
    "context_0_user = data[data[\"context_feature_id\"] == 0].user_id.unique()\n",
    "context_1_user = data[data[\"context_feature_id\"] == 1].user_id.unique()\n",
    "context_2_user = data[data[\"context_feature_id\"] == 2].user_id.unique()\n",
    "context_3_user = data[data[\"context_feature_id\"] == 3].user_id.unique()\n",
    "\n",
    "overlap_0_1 = len(set(context_0_user).intersection(set(context_1_user)))\n",
    "overlap_0_2 = len(set(context_0_user).intersection(set(context_2_user)))\n",
    "overlap_0_3 = len(set(context_0_user).intersection(set(context_3_user)))\n",
    "overlap_1_2 = len(set(context_1_user).intersection(set(context_2_user)))\n",
    "overlap_1_3 = len(set(context_1_user).intersection(set(context_3_user)))\n",
    "overlap_2_3 = len(set(context_2_user).intersection(set(context_3_user)))\n",
    "\n",
    "overlap_0 = overlap_0_1 + overlap_0_2 + overlap_0_3\n",
    "overlap_1 = overlap_0_1 + overlap_1_2 + overlap_1_3\n",
    "overlap_2 = overlap_0_2 + overlap_1_2 + overlap_2_3\n",
    "overlap_3 = overlap_0_3 + overlap_1_3 + overlap_2_3\n",
    "\n",
    "dict_overlap = {0:overlap_0, 1: overlap_1, 2: overlap_2, 3: overlap_3}\n",
    "\n",
    "df_overlap = pd.DataFrame(data.context_feature_id.value_counts())\n",
    "df_overlap.rename(columns={\"context_feature_id\": \"unique_cout\"}, inplace=True)\n",
    "df_overlap['context_feature_id']= df_overlap.index\n",
    "df_overlap['overlap'] = df_overlap['context_feature_id'].map(dict_overlap)\n",
    "df_overlap['overlap_percent'] = df_overlap['overlap'] / df_overlap['unique_cout'] * 100\n",
    "df_overlap.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191dd6cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:33.078339Z",
     "start_time": "2022-02-15T03:32:33.073132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_cout</th>\n",
       "      <th>context_feature_id</th>\n",
       "      <th>overlap</th>\n",
       "      <th>overlap_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458127</td>\n",
       "      <td>2</td>\n",
       "      <td>130149</td>\n",
       "      <td>28.408935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227138</td>\n",
       "      <td>1</td>\n",
       "      <td>61696</td>\n",
       "      <td>27.162342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142446</td>\n",
       "      <td>3</td>\n",
       "      <td>109428</td>\n",
       "      <td>76.820690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64660</td>\n",
       "      <td>0</td>\n",
       "      <td>27951</td>\n",
       "      <td>43.227652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_cout  context_feature_id  overlap  overlap_percent\n",
       "0       458127                   2   130149        28.408935\n",
       "1       227138                   1    61696        27.162342\n",
       "2       142446                   3   109428        76.820690\n",
       "3        64660                   0    27951        43.227652"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8825a9f",
   "metadata": {},
   "source": [
    "As shown above, many users are specific to only one context. So random sampling context_feature_id is not reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb3f40",
   "metadata": {},
   "source": [
    "### Merge item_feature to data, and check if users like one feature will not like other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b8e5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:32:33.139812Z",
     "start_time": "2022-02-15T03:32:33.079258Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. merge data\n",
    "data = data.merge(item_feature, left_on='item_id', right_on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e153915a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.313823Z",
     "start_time": "2022-02-15T03:32:33.140723Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. check if users like one feature will not like other features\n",
    "values = []\n",
    "keys = []\n",
    "for feature in data['item_feature_id'].unique():\n",
    "    value = set(data[data['item_feature_id'] == feature].user_id.unique())\n",
    "    values.append(value)\n",
    "    keys.append(feature)\n",
    "itemfeature_user_dict = dict(zip(keys, values))\n",
    "\n",
    "import copy\n",
    "itemfeature_user_overlap_percent = []\n",
    "itemfeature = []\n",
    "for key in itemfeature_user_dict:\n",
    "    itemfeature_user_dict_copy = copy.deepcopy(itemfeature_user_dict)\n",
    "    del itemfeature_user_dict_copy[key]\n",
    "    a = set()\n",
    "    for v_set in itemfeature_user_dict_copy.values():\n",
    "        for v in v_set:\n",
    "            a.add(v) # add all user ids in other features\n",
    "    percent = len(itemfeature_user_dict[key].intersection(a)) / len(itemfeature_user_dict[key]) * 100\n",
    "    itemfeature_user_overlap_percent.append(percent)\n",
    "    itemfeature.append(key)\n",
    "itemfeature_user_overlap_mapper = dict(zip(itemfeature, itemfeature_user_overlap_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d50da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.324699Z",
     "start_time": "2022-02-15T03:33:33.315197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. add overlap to dataframe\n",
    "df_overlap_itemfeature = pd.DataFrame(data.item_feature_id.value_counts())\n",
    "df_overlap_itemfeature.rename(columns={\"item_feature_id\": \"unique_cout\"}, inplace=True)\n",
    "df_overlap_itemfeature['item_feature_id']= df_overlap_itemfeature.index\n",
    "df_overlap_itemfeature['overlap'] = df_overlap_itemfeature['item_feature_id']\\\n",
    ".map(itemfeature_user_overlap_mapper)\n",
    "df_overlap_itemfeature.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26de192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.336853Z",
     "start_time": "2022-02-15T03:33:33.325935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_cout</th>\n",
       "      <th>item_feature_id</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10740</td>\n",
       "      <td>3</td>\n",
       "      <td>11.695685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29093</td>\n",
       "      <td>6</td>\n",
       "      <td>13.042855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15919</td>\n",
       "      <td>20</td>\n",
       "      <td>14.668874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110862</td>\n",
       "      <td>142</td>\n",
       "      <td>15.978653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13045</td>\n",
       "      <td>124</td>\n",
       "      <td>20.084467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4635</td>\n",
       "      <td>18</td>\n",
       "      <td>20.498915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11721</td>\n",
       "      <td>131</td>\n",
       "      <td>23.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15836</td>\n",
       "      <td>165</td>\n",
       "      <td>23.509934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3143</td>\n",
       "      <td>56</td>\n",
       "      <td>23.609227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>134</td>\n",
       "      <td>44</td>\n",
       "      <td>24.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3060</td>\n",
       "      <td>72</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>353</td>\n",
       "      <td>135</td>\n",
       "      <td>26.732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8799</td>\n",
       "      <td>147</td>\n",
       "      <td>27.907869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25475</td>\n",
       "      <td>55</td>\n",
       "      <td>28.482503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22455</td>\n",
       "      <td>153</td>\n",
       "      <td>28.520930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25116</td>\n",
       "      <td>129</td>\n",
       "      <td>30.744517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3942</td>\n",
       "      <td>34</td>\n",
       "      <td>31.189084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>608</td>\n",
       "      <td>30</td>\n",
       "      <td>31.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2609</td>\n",
       "      <td>132</td>\n",
       "      <td>34.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24924</td>\n",
       "      <td>84</td>\n",
       "      <td>34.580012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>231</td>\n",
       "      <td>140</td>\n",
       "      <td>34.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16630</td>\n",
       "      <td>144</td>\n",
       "      <td>35.024789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>477</td>\n",
       "      <td>42</td>\n",
       "      <td>35.537190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33686</td>\n",
       "      <td>1</td>\n",
       "      <td>35.665770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4356</td>\n",
       "      <td>64</td>\n",
       "      <td>36.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>583</td>\n",
       "      <td>50</td>\n",
       "      <td>37.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1476</td>\n",
       "      <td>98</td>\n",
       "      <td>37.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1185</td>\n",
       "      <td>180</td>\n",
       "      <td>38.317757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1862</td>\n",
       "      <td>115</td>\n",
       "      <td>40.181269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>427</td>\n",
       "      <td>80</td>\n",
       "      <td>40.860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6397</td>\n",
       "      <td>130</td>\n",
       "      <td>41.323210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>155</td>\n",
       "      <td>88</td>\n",
       "      <td>41.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>208</td>\n",
       "      <td>95</td>\n",
       "      <td>43.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2590</td>\n",
       "      <td>149</td>\n",
       "      <td>44.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2301</td>\n",
       "      <td>13</td>\n",
       "      <td>44.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10840</td>\n",
       "      <td>36</td>\n",
       "      <td>45.060512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1009</td>\n",
       "      <td>194</td>\n",
       "      <td>45.150502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1756</td>\n",
       "      <td>100</td>\n",
       "      <td>46.076795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>47.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102924</td>\n",
       "      <td>139</td>\n",
       "      <td>48.520303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29725</td>\n",
       "      <td>176</td>\n",
       "      <td>50.261917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5224</td>\n",
       "      <td>174</td>\n",
       "      <td>50.555850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1721</td>\n",
       "      <td>93</td>\n",
       "      <td>50.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60326</td>\n",
       "      <td>63</td>\n",
       "      <td>52.038945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>436</td>\n",
       "      <td>168</td>\n",
       "      <td>53.278689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1926</td>\n",
       "      <td>122</td>\n",
       "      <td>57.299270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86405</td>\n",
       "      <td>148</td>\n",
       "      <td>57.816556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3063</td>\n",
       "      <td>74</td>\n",
       "      <td>58.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>59.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>226</td>\n",
       "      <td>82</td>\n",
       "      <td>59.574468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>59</td>\n",
       "      <td>186</td>\n",
       "      <td>60.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>629</td>\n",
       "      <td>170</td>\n",
       "      <td>61.085973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>390</td>\n",
       "      <td>126</td>\n",
       "      <td>61.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9204</td>\n",
       "      <td>68</td>\n",
       "      <td>62.417375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>17</td>\n",
       "      <td>189</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>185</td>\n",
       "      <td>61</td>\n",
       "      <td>63.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1074</td>\n",
       "      <td>167</td>\n",
       "      <td>63.380282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>26</td>\n",
       "      <td>182</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>225</td>\n",
       "      <td>106</td>\n",
       "      <td>63.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18448</td>\n",
       "      <td>2</td>\n",
       "      <td>64.367816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>135</td>\n",
       "      <td>73</td>\n",
       "      <td>64.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1066</td>\n",
       "      <td>121</td>\n",
       "      <td>65.109034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>125</td>\n",
       "      <td>146</td>\n",
       "      <td>65.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8713</td>\n",
       "      <td>19</td>\n",
       "      <td>65.800416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3530</td>\n",
       "      <td>33</td>\n",
       "      <td>66.207627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>52</td>\n",
       "      <td>178</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>17</td>\n",
       "      <td>181</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1878</td>\n",
       "      <td>187</td>\n",
       "      <td>66.835017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>421</td>\n",
       "      <td>109</td>\n",
       "      <td>69.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>61</td>\n",
       "      <td>28</td>\n",
       "      <td>70.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>169</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>369</td>\n",
       "      <td>22</td>\n",
       "      <td>72.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1346</td>\n",
       "      <td>151</td>\n",
       "      <td>76.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>205</td>\n",
       "      <td>143</td>\n",
       "      <td>76.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>153</td>\n",
       "      <td>86</td>\n",
       "      <td>77.192982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2713</td>\n",
       "      <td>104</td>\n",
       "      <td>77.618621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>17</td>\n",
       "      <td>152</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44393</td>\n",
       "      <td>138</td>\n",
       "      <td>79.883863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>414</td>\n",
       "      <td>54</td>\n",
       "      <td>82.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4331</td>\n",
       "      <td>111</td>\n",
       "      <td>82.606023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2840</td>\n",
       "      <td>9</td>\n",
       "      <td>82.710280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>506</td>\n",
       "      <td>41</td>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>11</td>\n",
       "      <td>85</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1623</td>\n",
       "      <td>173</td>\n",
       "      <td>84.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>356</td>\n",
       "      <td>150</td>\n",
       "      <td>86.792453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>156</td>\n",
       "      <td>67</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>23</td>\n",
       "      <td>87</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>17</td>\n",
       "      <td>191</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>252</td>\n",
       "      <td>16</td>\n",
       "      <td>87.919463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>536</td>\n",
       "      <td>92</td>\n",
       "      <td>88.625592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6330</td>\n",
       "      <td>52</td>\n",
       "      <td>89.119336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>53</td>\n",
       "      <td>134</td>\n",
       "      <td>90.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18206</td>\n",
       "      <td>94</td>\n",
       "      <td>91.148537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2799</td>\n",
       "      <td>62</td>\n",
       "      <td>91.610284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2999</td>\n",
       "      <td>120</td>\n",
       "      <td>92.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1277</td>\n",
       "      <td>53</td>\n",
       "      <td>92.828685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>83</td>\n",
       "      <td>127</td>\n",
       "      <td>92.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>93.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1241</td>\n",
       "      <td>156</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>57</td>\n",
       "      <td>163</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7128</td>\n",
       "      <td>75</td>\n",
       "      <td>94.750977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1367</td>\n",
       "      <td>190</td>\n",
       "      <td>95.033113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3617</td>\n",
       "      <td>154</td>\n",
       "      <td>95.096322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1479</td>\n",
       "      <td>108</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1601</td>\n",
       "      <td>25</td>\n",
       "      <td>95.377129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>369</td>\n",
       "      <td>5</td>\n",
       "      <td>95.412844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3382</td>\n",
       "      <td>4</td>\n",
       "      <td>96.457533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16844</td>\n",
       "      <td>11</td>\n",
       "      <td>96.591807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1452</td>\n",
       "      <td>35</td>\n",
       "      <td>96.674584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1419</td>\n",
       "      <td>10</td>\n",
       "      <td>97.005988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>660</td>\n",
       "      <td>46</td>\n",
       "      <td>97.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>233</td>\n",
       "      <td>116</td>\n",
       "      <td>98.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>502</td>\n",
       "      <td>158</td>\n",
       "      <td>99.365751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>422</td>\n",
       "      <td>192</td>\n",
       "      <td>99.755501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>125</td>\n",
       "      <td>171</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>123</td>\n",
       "      <td>110</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>84</td>\n",
       "      <td>45</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>82</td>\n",
       "      <td>123</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>74</td>\n",
       "      <td>175</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>34</td>\n",
       "      <td>105</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10</td>\n",
       "      <td>159</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>9</td>\n",
       "      <td>155</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>162</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_cout  item_feature_id     overlap\n",
       "158            3              133    0.000000\n",
       "21         10740                3   11.695685\n",
       "7          29093                6   13.042855\n",
       "16         15919               20   14.668874\n",
       "0         110862              142   15.978653\n",
       "18         13045              124   20.084467\n",
       "29          4635               18   20.498915\n",
       "19         11721              131   23.076923\n",
       "17         15836              165   23.509934\n",
       "36          3143               56   23.609227\n",
       "97           134               44   24.242424\n",
       "38          3060               72   25.000000\n",
       "82           353              135   26.732673\n",
       "23          8799              147   27.907869\n",
       "8          25475               55   28.482503\n",
       "11         22455              153   28.520930\n",
       "9          25116              129   30.744517\n",
       "32          3942               34   31.189084\n",
       "67           608               30   31.746032\n",
       "43          2609              132   34.558824\n",
       "10         24924               84   34.580012\n",
       "85           231              140   34.920635\n",
       "15         16630              144   35.024789\n",
       "72           477               42   35.537190\n",
       "5          33686                1   35.665770\n",
       "30          4356               64   36.020408\n",
       "68           583               50   37.333333\n",
       "54          1476               98   37.368421\n",
       "61          1185              180   38.317757\n",
       "48          1862              115   40.181269\n",
       "74           427               80   40.860215\n",
       "26          6397              130   41.323210\n",
       "94           155               88   41.860465\n",
       "88           208               95   43.859649\n",
       "44          2590              149   44.376900\n",
       "45          2301               13   44.500000\n",
       "20         10840               36   45.060512\n",
       "64          1009              194   45.150502\n",
       "49          1756              100   46.076795\n",
       "108           66               17   47.368421\n",
       "1         102924              139   48.520303\n",
       "6          29725              176   50.261917\n",
       "28          5224              174   50.555850\n",
       "50          1721               93   50.851064\n",
       "3          60326               63   52.038945\n",
       "73           436              168   53.278689\n",
       "46          1926              122   57.299270\n",
       "2          86405              148   57.816556\n",
       "37          3063               74   58.045977\n",
       "106           70               43   59.375000\n",
       "86           226               82   59.574468\n",
       "110           59              186   60.869565\n",
       "66           629              170   61.085973\n",
       "78           390              126   61.481481\n",
       "22          9204               68   62.417375\n",
       "129           17              189   62.500000\n",
       "91           185               61   63.157895\n",
       "62          1074              167   63.380282\n",
       "120           26              182   63.636364\n",
       "87           225              106   63.750000\n",
       "12         18448                2   64.367816\n",
       "96           135               73   64.705882\n",
       "63          1066              121   65.109034\n",
       "99           125              146   65.789474\n",
       "24          8713               19   65.800416\n",
       "34          3530               33   66.207627\n",
       "90           200                7   66.233766\n",
       "113           52              178   66.666667\n",
       "122           24               21   66.666667\n",
       "101           89               89   66.666667\n",
       "130           17              181   66.666667\n",
       "155            4              117   66.666667\n",
       "146            6               26   66.666667\n",
       "47          1878              187   66.835017\n",
       "76           421              109   69.886364\n",
       "109           61               28   70.588235\n",
       "136           12              169   71.428571\n",
       "133           14               71   71.428571\n",
       "79           369               22   72.784810\n",
       "58          1346              151   76.388889\n",
       "89           205              143   76.712329\n",
       "95           153               86   77.192982\n",
       "42          2713              104   77.618621\n",
       "127           17              152   77.777778\n",
       "141           10              101   77.777778\n",
       "4          44393              138   79.883863\n",
       "118           32               59   81.818182\n",
       "77           414               54   82.352941\n",
       "31          4331              111   82.606023\n",
       "40          2840                9   82.710280\n",
       "70           506               41   82.857143\n",
       "139           11               85   83.333333\n",
       "144            9               60   83.333333\n",
       "51          1623              173   84.285714\n",
       "81           356              150   86.792453\n",
       "93           156               67   87.500000\n",
       "137           12               15   87.500000\n",
       "123           23               87   87.500000\n",
       "128           17              191   87.500000\n",
       "131           15               14   87.500000\n",
       "83           252               16   87.919463\n",
       "69           536               92   88.625592\n",
       "27          6330               52   89.119336\n",
       "121           26               31   89.473684\n",
       "92           156              157   89.473684\n",
       "112           53              134   90.625000\n",
       "115           43               29   90.909091\n",
       "13         18206               94   91.148537\n",
       "41          2799               62   91.610284\n",
       "134           13              103   91.666667\n",
       "39          2999              120   92.771084\n",
       "59          1277               53   92.828685\n",
       "103           83              127   92.857143\n",
       "114           50               38   93.023256\n",
       "116           39               97   94.117647\n",
       "60          1241              156   94.736842\n",
       "111           57              163   94.736842\n",
       "25          7128               75   94.750977\n",
       "57          1367              190   95.033113\n",
       "33          3617              154   95.096322\n",
       "53          1479              108   95.238095\n",
       "52          1601               25   95.377129\n",
       "80           369                5   95.412844\n",
       "35          3382                4   96.457533\n",
       "14         16844               11   96.591807\n",
       "55          1452               35   96.674584\n",
       "56          1419               10   97.005988\n",
       "65           660               46   97.972973\n",
       "84           233              116   98.148148\n",
       "71           502              158   99.365751\n",
       "75           422              192   99.755501\n",
       "177            1                8  100.000000\n",
       "157            3               32  100.000000\n",
       "174            1               48  100.000000\n",
       "159            3               91  100.000000\n",
       "160            3              160  100.000000\n",
       "161            2               27  100.000000\n",
       "162            2               47  100.000000\n",
       "156            3               37  100.000000\n",
       "163            2              161  100.000000\n",
       "164            2              113  100.000000\n",
       "165            2               99  100.000000\n",
       "166            2               66  100.000000\n",
       "170            1              119  100.000000\n",
       "167            2              118  100.000000\n",
       "173            1               57  100.000000\n",
       "168            2               69  100.000000\n",
       "172            1              172  100.000000\n",
       "169            2                0  100.000000\n",
       "171            1              188  100.000000\n",
       "180            1              164  100.000000\n",
       "179            1              184  100.000000\n",
       "178            1              125  100.000000\n",
       "176            1               81  100.000000\n",
       "175            1              136  100.000000\n",
       "119           26               23  100.000000\n",
       "153            4              137  100.000000\n",
       "181            1              114  100.000000\n",
       "98           125              171  100.000000\n",
       "100          123              110  100.000000\n",
       "102           84               45  100.000000\n",
       "104           82              123  100.000000\n",
       "105           74              175  100.000000\n",
       "107           68               12  100.000000\n",
       "117           34              105  100.000000\n",
       "124           21              102  100.000000\n",
       "125           20              145  100.000000\n",
       "126           19               58  100.000000\n",
       "154            4               24  100.000000\n",
       "132           14               76  100.000000\n",
       "138           12               77  100.000000\n",
       "140           10              159  100.000000\n",
       "142           10               79  100.000000\n",
       "143            9              155  100.000000\n",
       "145            7               39  100.000000\n",
       "147            6               65  100.000000\n",
       "148            5               51  100.000000\n",
       "149            4              166  100.000000\n",
       "150            4               49  100.000000\n",
       "151            4               96  100.000000\n",
       "152            4              179  100.000000\n",
       "135           12              162  100.000000\n",
       "182            1              185  100.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overlap_itemfeature.sort_values('overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca48e9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.343731Z",
     "start_time": "2022-02-15T03:33:33.339006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30847371776985133"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overlap_itemfeature[df_overlap_itemfeature['overlap'] < 30]['unique_cout'].sum() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7dc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T07:39:43.035879Z",
     "start_time": "2022-02-12T07:39:43.011304Z"
    }
   },
   "source": [
    "only 30% users like small user-overlap item features (overlap < 30%). So random sampling item features should be OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8b240",
   "metadata": {},
   "source": [
    "### rating = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b091dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.347316Z",
     "start_time": "2022-02-15T03:33:33.344657Z"
    }
   },
   "outputs": [],
   "source": [
    "data['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84198982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.354896Z",
     "start_time": "2022-02-15T03:33:33.348198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "      <th>item_feature_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20750</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8759</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892366</th>\n",
       "      <td>200150</td>\n",
       "      <td>20387</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892367</th>\n",
       "      <td>200152</td>\n",
       "      <td>30710</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892368</th>\n",
       "      <td>200152</td>\n",
       "      <td>12006</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892369</th>\n",
       "      <td>200152</td>\n",
       "      <td>25030</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892370</th>\n",
       "      <td>200152</td>\n",
       "      <td>14578</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892371 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  context_feature_id  item_feature_id  rating\n",
       "0             0    28366                   2                7       1\n",
       "1             0    16109                   2                7       1\n",
       "2             0    11500                   3                7       1\n",
       "3             0    20750                   2                7       1\n",
       "4             0     8759                   2                7       1\n",
       "...         ...      ...                 ...              ...     ...\n",
       "892366   200150    20387                   2                2       1\n",
       "892367   200152    30710                   2              148       1\n",
       "892368   200152    12006                   2              148       1\n",
       "892369   200152    25030                   2              148       1\n",
       "892370   200152    14578                   2              148       1\n",
       "\n",
       "[892371 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3d115",
   "metadata": {},
   "source": [
    "## MF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc4d02",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4920cced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.447130Z",
     "start_time": "2022-02-15T03:33:33.355945Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Popularity sampling\n",
    "uniqs, counts = np.unique(data['item_id'], return_counts=True)\n",
    "total_count = sum(counts)\n",
    "item_probabilities = [0]*(data['item_id'].max()+1) # tweak\n",
    "for item, count in zip(uniqs, counts):\n",
    "    item_probabilities[item] = count / total_count\n",
    "item_probabilities = np.array(item_probabilities)\n",
    "item_list = np.array((range(data['item_id'].max()+1)))\n",
    "\n",
    "item_prob_max = item_probabilities.max()\n",
    "item_prob_min = item_probabilities[item_probabilities>0].min()\n",
    "item_prob_1_4th = np.quantile(item_probabilities[item_probabilities > 0], 0.25)\n",
    "item_prob_2_4th = np.quantile(item_probabilities[item_probabilities > 0], 0.5)\n",
    "item_prob_3_4th = np.quantile(item_probabilities[item_probabilities > 0], 0.75)\n",
    "\n",
    "item_nesample_num = [0] * len(item_probabilities)\n",
    "for i, item_prob in enumerate(list(item_probabilities)):\n",
    "    if item_prob < item_prob_min:\n",
    "        item_nesample_num[i] = 0\n",
    "    elif item_prob <= item_prob_1_4th:\n",
    "        item_nesample_num[i] = 6\n",
    "    elif item_prob <= item_prob_2_4th:\n",
    "        item_nesample_num[i] = 5\n",
    "    elif item_prob <= item_prob_3_4th:\n",
    "        item_nesample_num[i] = 4\n",
    "    else:\n",
    "        item_nesample_num[i] = 2\n",
    "item_nesample_mapper = dict(zip(item_list, item_nesample_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "248fda0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.454618Z",
     "start_time": "2022-02-15T03:33:33.448414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 5, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(item_nesample_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c6a6e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:33.644606Z",
     "start_time": "2022-02-15T03:33:33.455422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1923.,     0.,     0.,  9181.,     0.,     0.,  7373.,     0.,\n",
       "         9329., 12095.]),\n",
       " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(item_nesample_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8b8193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:41.283468Z",
     "start_time": "2022-02-15T03:33:33.645481Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 892371/892371 [00:02<00:00, 327940.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. Negetive sampling and create df\n",
    "import random\n",
    "item_item_feature_map = data[['item_id', 'item_feature_id']].set_index('item_id').to_dict()['item_feature_id']\n",
    "data['rating'] = 1\n",
    "df_ = data.set_index(['user_id', 'item_id', 'context_feature_id', 'item_feature_id'])\n",
    "df_dict = df_['rating'].to_dict()\n",
    "item_unique = list(set(data['item_id']))\n",
    "users, items, context_features, item_features, ratings = [], [], [], [], []\n",
    "for (u, i, c, f) in tqdm(df_dict.keys()):\n",
    "    # positives\n",
    "    users.append(u)\n",
    "    items.append(i)\n",
    "    context_features.append(c)\n",
    "    item_features.append(f)\n",
    "    ratings.append(1)\n",
    "    # negatives\n",
    "    num_negative = item_nesample_mapper[i]\n",
    "    for _ in range(num_negative):\n",
    "        j = random.choice(item_unique)\n",
    "        \n",
    "        while (u, j, c, f) in df_dict: #or item_item_feature_map[j] == f:\n",
    "            j = random.choice(item_unique)\n",
    "            \n",
    "        users.append(u)\n",
    "        items.append(j)\n",
    "        context_features.append(c)\n",
    "        item_features.append(f)\n",
    "        ratings.append(0)\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['user'] = users\n",
    "df['item'] = items\n",
    "df['context_feature'] = context_features\n",
    "df['item_feature'] = item_features\n",
    "df['rating'] = ratings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f1a0928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:41.291521Z",
     "start_time": "2022-02-15T03:33:41.284639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>context_feature</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31012</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17834</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30744</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872723</th>\n",
       "      <td>200152</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872724</th>\n",
       "      <td>200152</td>\n",
       "      <td>17077</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872725</th>\n",
       "      <td>200152</td>\n",
       "      <td>14578</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872726</th>\n",
       "      <td>200152</td>\n",
       "      <td>36498</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872727</th>\n",
       "      <td>200152</td>\n",
       "      <td>16932</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2872728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item  context_feature  item_feature  rating\n",
       "0             0  28366                2             7       1\n",
       "1             0  31012                2             7       0\n",
       "2             0  17834                2             7       0\n",
       "3             0  16109                2             7       1\n",
       "4             0  30744                2             7       0\n",
       "...         ...    ...              ...           ...     ...\n",
       "2872723  200152     27                2           148       0\n",
       "2872724  200152  17077                2           148       0\n",
       "2872725  200152  14578                2           148       1\n",
       "2872726  200152  36498                2           148       0\n",
       "2872727  200152  16932                2           148       0\n",
       "\n",
       "[2872728 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63588151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T08:41:42.202571Z",
     "start_time": "2022-02-12T08:41:42.199396Z"
    }
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "315b2010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:41.299286Z",
     "start_time": "2022-02-15T03:33:41.292229Z"
    }
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, seed=23):\n",
    "        super(MF, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.user_emb = nn.Embedding(num_users+1, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users+1, 1)\n",
    "        self.item_emb = nn.Embedding(num_items+1, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items+1, 1)\n",
    "        \n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        ### BEGIN SOLUTION\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        logits = (U*V).sum(1) + b_u  + b_v\n",
    "        return torch.sigmoid(logits)\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62f45d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:41.310926Z",
     "start_time": "2022-02-15T03:33:41.306713Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_df, optimizer, feature_flag=False):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    users = torch.LongTensor(train_df['user'].values)  #.cuda()\n",
    "    items = torch.LongTensor(train_df['item'].values) #.cuda()\n",
    "    ratings = torch.FloatTensor(train_df['rating'].values)  #.cuda()\n",
    "\n",
    "    if feature_flag == True:\n",
    "        item_feature = torch.LongTensor(train_df['item_feature'].values) #.cuda()\n",
    "        context_feature = torch.LongTensor(train_df['context_feature'].values) #.cuda()\n",
    "        y_hat = model(users, items, item_feature, context_feature)\n",
    "    else:\n",
    "        y_hat = model(users, items)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    ### END SOLUTION\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0515dc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:33:41.315423Z",
     "start_time": "2022-02-15T03:33:41.312127Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, train_df, epochs=10, lr=0.01, wd=0.0, feature_flag=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch(model, train_df, optimizer, feature_flag)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "279d36a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:13.349633Z",
     "start_time": "2022-02-15T03:33:41.316366Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.699\n",
      "train loss 0.734\n",
      "train loss 0.593\n",
      "train loss 0.546\n",
      "train loss 0.504\n",
      "train loss 0.431\n",
      "train loss 0.363\n",
      "train loss 0.320\n",
      "train loss 0.299\n",
      "train loss 0.286\n",
      "train loss 0.276\n",
      "train loss 0.270\n",
      "train loss 0.264\n",
      "train loss 0.257\n",
      "train loss 0.248\n",
      "train loss 0.239\n",
      "train loss 0.229\n",
      "train loss 0.222\n",
      "train loss 0.216\n",
      "train loss 0.211\n",
      "train loss 0.208\n",
      "train loss 0.206\n",
      "train loss 0.203\n",
      "train loss 0.201\n",
      "train loss 0.198\n",
      "train loss 0.194\n",
      "train loss 0.191\n",
      "train loss 0.186\n",
      "train loss 0.182\n",
      "train loss 0.178\n",
      "train loss 0.174\n",
      "train loss 0.171\n",
      "train loss 0.169\n",
      "train loss 0.167\n",
      "train loss 0.166\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "model = MF(user_max, item_max, emb_size=50) \n",
    "training(model, df, epochs=35, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805962d6",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eed3f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:13.384595Z",
     "start_time": "2022-02-15T03:34:13.350416Z"
    }
   },
   "outputs": [],
   "source": [
    "users = torch.LongTensor(test['user_id'].values)  #.cuda()\n",
    "items = torch.LongTensor(test['item_id'].values) #.cuda()\n",
    "#item_features = torch.LongTensor(test['item_feature_id'].values) #.cuda()\n",
    "context_features = torch.LongTensor(test['context_feature_id'].values) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc5b82e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:13.442982Z",
     "start_time": "2022-02-15T03:34:13.385513Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model(users, items).detach().numpy()\n",
    "test['rating']= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e92b17a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:13.450872Z",
     "start_time": "2022-02-15T03:34:13.443778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16835</td>\n",
       "      <td>2</td>\n",
       "      <td>0.391639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22590</td>\n",
       "      <td>3</td>\n",
       "      <td>0.347531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28916</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14427</td>\n",
       "      <td>2</td>\n",
       "      <td>0.164574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381380</th>\n",
       "      <td>381380</td>\n",
       "      <td>200151</td>\n",
       "      <td>1702</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381381</th>\n",
       "      <td>381381</td>\n",
       "      <td>200151</td>\n",
       "      <td>21632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381382</th>\n",
       "      <td>381382</td>\n",
       "      <td>200151</td>\n",
       "      <td>30477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381383</th>\n",
       "      <td>381383</td>\n",
       "      <td>200151</td>\n",
       "      <td>30477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381384</th>\n",
       "      <td>381384</td>\n",
       "      <td>200151</td>\n",
       "      <td>17715</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381385 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  user_id  item_id  context_feature_id    rating\n",
       "0            0        4    16835                   2  0.391639\n",
       "1            1        4    22590                   3  0.347531\n",
       "2            2        4     1978                   1  0.833119\n",
       "3            3        4    28916                   1  0.173881\n",
       "4            4        4    14427                   2  0.164574\n",
       "...        ...      ...      ...                 ...       ...\n",
       "381380  381380   200151     1702                   1  0.785238\n",
       "381381  381381   200151    21632                   1  0.861450\n",
       "381382  381382   200151    30477                   1  0.822168\n",
       "381383  381383   200151    30477                   1  0.822168\n",
       "381384  381384   200151    17715                   1  0.188085\n",
       "\n",
       "[381385 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5636b778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:13.456796Z",
     "start_time": "2022-02-15T03:34:13.452013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195259"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b15d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.078592Z",
     "start_time": "2022-02-15T03:34:13.457938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.485380914299199"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "sum(ypred_hard == 1) / len(ypred_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e930dfc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.669815Z",
     "start_time": "2022-02-15T03:34:14.079387Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"predict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da80a1a",
   "metadata": {},
   "source": [
    "### Save embeddings and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "accfc70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.673166Z",
     "start_time": "2022-02-15T03:34:14.670833Z"
    }
   },
   "outputs": [],
   "source": [
    "user_embeddings = model.user_emb.weight.detach()\n",
    "item_embeddings = model.item_emb.weight.detach()\n",
    "user_bias = model.user_bias.weight.detach()\n",
    "item_bias = model.item_bias.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a78ec0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.676259Z",
     "start_time": "2022-02-15T03:34:14.673897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200153, 50]),\n",
       " torch.Size([39901, 50]),\n",
       " torch.Size([200153, 1]),\n",
       " torch.Size([39901, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings.shape, item_embeddings.shape, user_bias.shape, item_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c688f9b",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a6a2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:51:37.471925Z",
     "start_time": "2022-02-12T23:51:37.468658Z"
    }
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15b30c75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.679507Z",
     "start_time": "2022-02-15T03:34:14.677031Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid_metrics(model, users_val, items_val, ratings_val):\n",
    "    \"\"\"Computes validation loss and accuracy\"\"\"\n",
    "    model.eval()\n",
    "    ### BEGIN SOLUTION\n",
    "    y_hat = model(users_val, items_val)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings_val)\n",
    "    valid_loss = loss.item()\n",
    "\n",
    "    # Accuracy\n",
    "    y = ratings_val.detach().tolist()\n",
    "    ypred = y_hat.detach().tolist()\n",
    "\n",
    "    ### END SOLUTION\n",
    "    return ypred, y, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34f50f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.686445Z",
     "start_time": "2022-02-15T03:34:14.680418Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, df, optimizer, cv_n_split=10, cv_random_state=1, cv_shuffle=True):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    kf = KFold(n_splits=cv_n_split, random_state=cv_random_state, shuffle=cv_shuffle)\n",
    "    pred = []\n",
    "    ys = []\n",
    "    valid_loss_list = []\n",
    "    model.train()\n",
    "    for fold, (train_ids, val_ids) in enumerate(kf.split(df)):\n",
    "        users_train = torch.LongTensor(df['user'][train_ids].values)  #.cuda()\n",
    "        users_val = torch.LongTensor(df['user'][val_ids].values)  #.cuda()\n",
    "        items_train = torch.LongTensor(df['item'][train_ids].values) #.cuda()\n",
    "        items_val = torch.LongTensor(df['item'][val_ids].values)  #.cuda()\n",
    "        ratings_train = torch.FloatTensor(df['rating'][train_ids].values)  #.cuda()\n",
    "        ratings_val = torch.FloatTensor(df['rating'][val_ids].values)  #.cuda()\n",
    "        \n",
    "        y_train_hat = model(users_train, items_train)\n",
    "        loss = F.binary_cross_entropy(y_train_hat, ratings_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "        y_val_hat, y_val_true, valid_loss = valid_metrics(model, users_val, items_val, ratings_val)\n",
    "        \n",
    "        pred += y_val_hat\n",
    "        ys += y_val_true\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        print(f\"FOLD: {fold+1} train loss {train_loss:.3f}\")\n",
    "    \n",
    "    valid_loss_mean = np.array(valid_loss_list).mean()\n",
    "    ypred_hard = np.where(np.array(pred) >= 0.5, 1, 0)\n",
    "    valid_acc = np.sum(np.array(ys) == ypred_hard) / len(df)\n",
    "    ### END SOLUTION\n",
    "    return valid_loss_mean, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ebd04cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:34:14.690488Z",
     "start_time": "2022-02-15T03:34:14.687499Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, df, epochs=10, lr=0.01, wd=0.0, cv_n_split=10, cv_random_state=1, cv_shuffle=True):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        valid_loss, valid_acc = train_one_epoch(model, df, optimizer, \n",
    "                                                cv_n_split=cv_n_split, \n",
    "                                                cv_random_state=cv_random_state, \n",
    "                                                cv_shuffle=cv_shuffle)\n",
    "        print(f\"Epoch: {i+1} valid_loss {valid_loss:.3f} valid_acc {valid_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "526a17df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:05.067147Z",
     "start_time": "2022-02-15T03:34:14.691492Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 train loss 0.699\n",
      "FOLD: 2 train loss 0.732\n",
      "FOLD: 3 train loss 0.593\n",
      "FOLD: 4 train loss 0.547\n",
      "FOLD: 5 train loss 0.503\n",
      "Epoch: 1 valid_loss 0.562 valid_acc 0.771\n",
      "FOLD: 1 train loss 0.429\n",
      "FOLD: 2 train loss 0.362\n",
      "FOLD: 3 train loss 0.320\n",
      "FOLD: 4 train loss 0.300\n",
      "FOLD: 5 train loss 0.288\n",
      "Epoch: 2 valid_loss 0.311 valid_acc 0.893\n",
      "FOLD: 1 train loss 0.279\n",
      "FOLD: 2 train loss 0.274\n",
      "FOLD: 3 train loss 0.269\n",
      "FOLD: 4 train loss 0.263\n",
      "FOLD: 5 train loss 0.255\n",
      "Epoch: 3 valid_loss 0.260 valid_acc 0.916\n",
      "FOLD: 1 train loss 0.246\n",
      "FOLD: 2 train loss 0.236\n",
      "FOLD: 3 train loss 0.228\n",
      "FOLD: 4 train loss 0.221\n",
      "FOLD: 5 train loss 0.216\n",
      "Epoch: 4 valid_loss 0.221 valid_acc 0.942\n",
      "FOLD: 1 train loss 0.211\n",
      "FOLD: 2 train loss 0.208\n",
      "FOLD: 3 train loss 0.206\n",
      "FOLD: 4 train loss 0.203\n",
      "FOLD: 5 train loss 0.200\n",
      "Epoch: 5 valid_loss 0.202 valid_acc 0.960\n",
      "FOLD: 1 train loss 0.196\n",
      "FOLD: 2 train loss 0.192\n",
      "FOLD: 3 train loss 0.188\n",
      "FOLD: 4 train loss 0.184\n",
      "FOLD: 5 train loss 0.180\n",
      "Epoch: 6 valid_loss 0.183 valid_acc 0.968\n",
      "FOLD: 1 train loss 0.177\n",
      "FOLD: 2 train loss 0.174\n",
      "FOLD: 3 train loss 0.171\n",
      "FOLD: 4 train loss 0.169\n",
      "FOLD: 5 train loss 0.167\n",
      "Epoch: 7 valid_loss 0.168 valid_acc 0.968\n",
      "FOLD: 1 train loss 0.166\n",
      "FOLD: 2 train loss 0.166\n",
      "FOLD: 3 train loss 0.165\n",
      "FOLD: 4 train loss 0.165\n",
      "FOLD: 5 train loss 0.165\n",
      "Epoch: 8 valid_loss 0.164 valid_acc 0.967\n",
      "FOLD: 1 train loss 0.165\n",
      "FOLD: 2 train loss 0.165\n",
      "FOLD: 3 train loss 0.166\n",
      "FOLD: 4 train loss 0.166\n",
      "FOLD: 5 train loss 0.167\n",
      "Epoch: 9 valid_loss 0.165 valid_acc 0.969\n",
      "FOLD: 1 train loss 0.167\n",
      "FOLD: 2 train loss 0.168\n",
      "FOLD: 3 train loss 0.168\n",
      "FOLD: 4 train loss 0.168\n",
      "FOLD: 5 train loss 0.169\n",
      "Epoch: 10 valid_loss 0.168 valid_acc 0.970\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "model = MF(user_max, item_max, emb_size=50) \n",
    "training(model, df, epochs=10, lr=0.1, wd=1e-6, cv_n_split=5, cv_random_state=1, cv_shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41989ef",
   "metadata": {},
   "source": [
    "### Try fewer epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6410645c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:40.374260Z",
     "start_time": "2022-02-15T03:35:05.068021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 train loss 0.699\n",
      "FOLD: 2 train loss 0.732\n",
      "FOLD: 3 train loss 0.593\n",
      "FOLD: 4 train loss 0.547\n",
      "FOLD: 5 train loss 0.503\n",
      "Epoch: 1 valid_loss 0.562 valid_acc 0.771\n",
      "FOLD: 1 train loss 0.429\n",
      "FOLD: 2 train loss 0.362\n",
      "FOLD: 3 train loss 0.320\n",
      "FOLD: 4 train loss 0.300\n",
      "FOLD: 5 train loss 0.288\n",
      "Epoch: 2 valid_loss 0.311 valid_acc 0.893\n",
      "FOLD: 1 train loss 0.279\n",
      "FOLD: 2 train loss 0.274\n",
      "FOLD: 3 train loss 0.269\n",
      "FOLD: 4 train loss 0.263\n",
      "FOLD: 5 train loss 0.255\n",
      "Epoch: 3 valid_loss 0.260 valid_acc 0.916\n",
      "FOLD: 1 train loss 0.246\n",
      "FOLD: 2 train loss 0.236\n",
      "FOLD: 3 train loss 0.228\n",
      "FOLD: 4 train loss 0.221\n",
      "FOLD: 5 train loss 0.216\n",
      "Epoch: 4 valid_loss 0.221 valid_acc 0.942\n",
      "FOLD: 1 train loss 0.211\n",
      "FOLD: 2 train loss 0.208\n",
      "FOLD: 3 train loss 0.206\n",
      "FOLD: 4 train loss 0.203\n",
      "FOLD: 5 train loss 0.200\n",
      "Epoch: 5 valid_loss 0.202 valid_acc 0.960\n",
      "FOLD: 1 train loss 0.196\n",
      "FOLD: 2 train loss 0.192\n",
      "FOLD: 3 train loss 0.188\n",
      "FOLD: 4 train loss 0.184\n",
      "FOLD: 5 train loss 0.180\n",
      "Epoch: 6 valid_loss 0.183 valid_acc 0.968\n",
      "FOLD: 1 train loss 0.177\n",
      "FOLD: 2 train loss 0.174\n",
      "FOLD: 3 train loss 0.171\n",
      "FOLD: 4 train loss 0.169\n",
      "FOLD: 5 train loss 0.167\n",
      "Epoch: 7 valid_loss 0.168 valid_acc 0.968\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "model = MF(user_max, item_max, emb_size=50) \n",
    "training(model, df, epochs=7, lr=0.1, wd=1e-6, cv_n_split=5, cv_random_state=1, cv_shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3c097",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa82d8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:40.381040Z",
     "start_time": "2022-02-15T03:35:40.375159Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature = pd.read_csv('data/item_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dd26644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.029397Z",
     "start_time": "2022-02-15T03:35:40.381988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.520993\n",
      "0.487066874680441\n"
     ]
    }
   ],
   "source": [
    "users = torch.LongTensor(test['user_id'].values)  #.cuda()\n",
    "items = torch.LongTensor(test['item_id'].values) #.cuda()\n",
    "\n",
    "y_pred = model(users, items).detach().numpy()\n",
    "test['rating']= y_pred\n",
    "\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dfc4a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.614942Z",
     "start_time": "2022-02-15T03:35:41.030277Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"predict_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0a86e",
   "metadata": {},
   "source": [
    "Cross validation is no better than the previous result. If do trainning on the entire dataset, the best epoch should be35-40 to gain better result when embedding size is 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71c9f8",
   "metadata": {},
   "source": [
    "## MF on features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6904de1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1401aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.701612Z",
     "start_time": "2022-02-15T03:35:41.615788Z"
    }
   },
   "outputs": [],
   "source": [
    "item_feature = pd.read_csv('data/item_feature.csv')\n",
    "test = pd.read_csv('data/test_kaggle.csv')\n",
    "test = test.merge(item_feature, left_on='item_id', right_on='item_id', how='left')\n",
    "test.rename(columns={\"item_feature_id\": \"item_feature\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b278ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.707066Z",
     "start_time": "2022-02-15T03:35:41.702580Z"
    }
   },
   "outputs": [],
   "source": [
    "class MF_feature(nn.Module):\n",
    "    def __init__(self, num_context, num_item_feature, emb_size=10, seed=23):\n",
    "        super(MF_feature, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.context_emb = nn.Embedding(num_context+1, emb_size)\n",
    "        self.context_bias = nn.Embedding(num_context+1, 1)\n",
    "        self.item_feature_emb = nn.Embedding(num_item_feature+1, emb_size)\n",
    "        self.item_feature_bias = nn.Embedding(num_item_feature+1, 1)\n",
    "        \n",
    "        # init \n",
    "        self.context_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_feature_emb.weight.data.uniform_(0,0.05)\n",
    "        self.context_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_feature_bias.weight.data.uniform_(-0.01,0.01)\n",
    "\n",
    "    def forward(self, c, f):\n",
    "        ### BEGIN SOLUTION\n",
    "        C = self.context_emb(c)\n",
    "        F = self.item_feature_emb(f)\n",
    "        b_c = self.context_bias(c).squeeze()\n",
    "        b_f = self.item_feature_bias(f).squeeze()\n",
    "        logits = (C*F).sum(1) + b_c  + b_f\n",
    "        return torch.sigmoid(logits)\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6960ede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.710867Z",
     "start_time": "2022-02-15T03:35:41.707950Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_feature(model, df, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    context_features = torch.LongTensor(df['context_feature'].values)  #.cuda()\n",
    "    item_features = torch.LongTensor(df['item_feature'].values) #.cuda()\n",
    "    ratings = torch.FloatTensor(df['rating'].values)  #.cuda()\n",
    "    \n",
    "    y_hat = model(context_features, item_features)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    ### END SOLUTION\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec6a6dd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:35:41.714343Z",
     "start_time": "2022-02-15T03:35:41.711751Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_feature(model, df, epochs=10, lr=0.01, wd=0.0, feature_flag=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch_feature(model, df, optimizer)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "005d74e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:02.110998Z",
     "start_time": "2022-02-15T03:35:41.715236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.694\n",
      "train loss 0.689\n",
      "train loss 0.685\n",
      "train loss 0.682\n",
      "train loss 0.679\n",
      "train loss 0.675\n",
      "train loss 0.672\n",
      "train loss 0.669\n",
      "train loss 0.665\n",
      "train loss 0.662\n",
      "train loss 0.659\n",
      "train loss 0.656\n",
      "train loss 0.652\n",
      "train loss 0.649\n",
      "train loss 0.646\n",
      "train loss 0.643\n",
      "train loss 0.640\n",
      "train loss 0.637\n",
      "train loss 0.634\n",
      "train loss 0.631\n"
     ]
    }
   ],
   "source": [
    "context_feature_max = df['context_feature'].max()\n",
    "item_feature_max = df['item_feature'].max()\n",
    "model_feature = MF_feature(context_feature_max, item_feature_max, emb_size=10) \n",
    "training_feature(model_feature, df, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e93557",
   "metadata": {},
   "source": [
    "### Save embeddings and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72d12af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:02.114064Z",
     "start_time": "2022-02-15T03:36:02.111861Z"
    }
   },
   "outputs": [],
   "source": [
    "context_embeddings = model_feature.context_emb.weight.detach()\n",
    "item_feature_embeddings = model_feature.item_feature_emb.weight.detach()\n",
    "context_bias = model_feature.context_bias.weight.detach()\n",
    "item_feature_bias = model_feature.item_feature_bias.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c5e7b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:02.117376Z",
     "start_time": "2022-02-15T03:36:02.114919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10]),\n",
       " torch.Size([195, 10]),\n",
       " torch.Size([4, 1]),\n",
       " torch.Size([195, 1]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.size(), item_feature_embeddings.size(), context_bias.size(), item_feature_bias.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfe8e4",
   "metadata": {},
   "source": [
    "## NN model with extracted trained embedding (MF users+item, MF features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73180023",
   "metadata": {},
   "source": [
    "### Get vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a741c147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:21.953001Z",
     "start_time": "2022-02-15T03:36:02.118051Z"
    }
   },
   "outputs": [],
   "source": [
    "user_vector = user_embeddings[df['user']]\n",
    "item_vector = item_embeddings[df['item']]\n",
    "context_vector = context_embeddings[df['context_feature']]\n",
    "item_feature_vector = item_feature_embeddings[df['item_feature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1980e916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:21.956483Z",
     "start_time": "2022-02-15T03:36:21.953957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2872728, 50]),\n",
       " torch.Size([2872728, 50]),\n",
       " torch.Size([2872728, 10]),\n",
       " torch.Size([2872728, 10]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vector.shape, item_vector.shape, context_vector.shape, item_feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e137d215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:22.323063Z",
     "start_time": "2022-02-15T03:36:21.957232Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_vector = torch.cat([user_vector, item_vector, context_vector, item_feature_vector], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb7c58d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:22.329318Z",
     "start_time": "2022-02-15T03:36:22.324295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2829,  0.0020, -0.0806,  ...,  0.1501,  0.1136, -0.1244],\n",
       "        [-0.2829,  0.0020, -0.0806,  ...,  0.1501,  0.1136, -0.1244],\n",
       "        [-0.2829,  0.0020, -0.0806,  ...,  0.1501,  0.1136, -0.1244],\n",
       "        ...,\n",
       "        [-0.0188,  0.1603, -0.0535,  ...,  0.1520,  0.1103, -0.1201],\n",
       "        [-0.0188,  0.1603, -0.0535,  ...,  0.1520,  0.1103, -0.1201],\n",
       "        [-0.0188,  0.1603, -0.0535,  ...,  0.1520,  0.1103, -0.1201]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0f66b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a52723d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:22.333810Z",
     "start_time": "2022-02-15T03:36:22.330237Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nn = nn.Sequential(\n",
    "    nn.Linear(120, 60), \n",
    "    nn.Dropout(0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 15),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(15, 1),\n",
    "    nn.Sigmoid()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91f9d920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:22.337918Z",
     "start_time": "2022-02-15T03:36:22.334763Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_nn(model, df, concat_vector, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    ratings = torch.FloatTensor(df['rating'].values).unsqueeze(1)  #.cuda()\n",
    "    \n",
    "    y_hat = model(concat_vector)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    ### END SOLUTION\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40985bad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:36:22.341595Z",
     "start_time": "2022-02-15T03:36:22.338947Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_nn(model, df, concat_vector, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch_nn(model, df, concat_vector, optimizer)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f5a534a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:11.944587Z",
     "start_time": "2022-02-15T03:36:22.342507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.714\n",
      "train loss 0.693\n",
      "train loss 0.668\n",
      "train loss 0.636\n",
      "train loss 0.606\n",
      "train loss 0.585\n",
      "train loss 0.574\n",
      "train loss 0.561\n",
      "train loss 0.540\n",
      "train loss 0.512\n",
      "train loss 0.479\n",
      "train loss 0.445\n",
      "train loss 0.419\n",
      "train loss 0.407\n",
      "train loss 0.406\n",
      "train loss 0.412\n",
      "train loss 0.420\n",
      "train loss 0.422\n",
      "train loss 0.414\n",
      "train loss 0.402\n",
      "train loss 0.388\n",
      "train loss 0.378\n",
      "train loss 0.375\n",
      "train loss 0.377\n",
      "train loss 0.378\n",
      "train loss 0.375\n",
      "train loss 0.369\n",
      "train loss 0.362\n",
      "train loss 0.353\n",
      "train loss 0.346\n"
     ]
    }
   ],
   "source": [
    "model_nn = nn.Sequential(\n",
    "    nn.Linear(120, 60), \n",
    "    nn.Dropout(0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 15),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(15, 1),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "training_nn(model_nn, df, concat_vector, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f7619",
   "metadata": {},
   "source": [
    "### Predict (get embedding for test first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0661ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:15.287042Z",
     "start_time": "2022-02-15T03:39:11.946262Z"
    }
   },
   "outputs": [],
   "source": [
    "test_user_vector = user_embeddings[test['user_id']]\n",
    "test_item_vector = item_embeddings[test['item_id']]\n",
    "test_context_vector = context_embeddings[test['context_feature_id']]\n",
    "test_item_feature_vector = item_feature_embeddings[test['item_feature']]\n",
    "test_concat_vector = torch.cat([test_user_vector, test_item_vector, \n",
    "                                test_context_vector, test_item_feature_vector], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8267fd3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:15.823762Z",
     "start_time": "2022-02-15T03:39:15.287819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46583182\n",
      "[0.38084875]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_nn(test_concat_vector).detach().numpy()\n",
    "test['rating']= y_pred\n",
    "\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7beeb6",
   "metadata": {},
   "source": [
    "## NN model added in MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f414c4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:15.829826Z",
     "start_time": "2022-02-15T03:39:15.824683Z"
    }
   },
   "outputs": [],
   "source": [
    "class MF_nn(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=50, seed=23):\n",
    "        super(MF_nn, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.user_emb = nn.Embedding(num_users+1, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users+1, 1)\n",
    "        self.item_emb = nn.Embedding(num_items+1, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items+1, 1)\n",
    "        self.linear1 = nn.Linear(100, 50)\n",
    "        self.linear2 = nn.Linear(50, 25)\n",
    "        self.linear3 = nn.Linear(25, 1)\n",
    "        \n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        ### BEGIN SOLUTION\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        \n",
    "        x = torch.cat([U, V], 1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29d5133a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:15.834165Z",
     "start_time": "2022-02-15T03:39:15.830848Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_mf_nn(model, train_df, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    users = torch.LongTensor(train_df['user'].values)  #.cuda()\n",
    "    items = torch.LongTensor(train_df['item'].values) #.cuda()\n",
    "    ratings = torch.FloatTensor(train_df['rating'].values).unsqueeze(1)  #.cuda()\n",
    "\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    ### END SOLUTION\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2e87e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:39:15.837912Z",
     "start_time": "2022-02-15T03:39:15.835208Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_mf_nn(model, train_df, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch_mf_nn(model, train_df, optimizer)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc18fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:00.917031Z",
     "start_time": "2022-02-15T03:39:15.838844Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.698\n",
      "train loss 0.613\n",
      "train loss 1.889\n",
      "train loss 0.391\n",
      "train loss 0.668\n",
      "train loss 0.504\n",
      "train loss 0.361\n",
      "train loss 0.368\n",
      "train loss 0.366\n",
      "train loss 0.326\n",
      "train loss 0.335\n",
      "train loss 0.356\n",
      "train loss 0.329\n",
      "train loss 0.303\n",
      "train loss 0.314\n",
      "train loss 0.305\n",
      "train loss 0.292\n",
      "train loss 0.291\n",
      "train loss 0.301\n",
      "train loss 0.300\n",
      "train loss 0.288\n",
      "train loss 0.289\n",
      "train loss 0.303\n",
      "train loss 0.286\n",
      "train loss 0.295\n",
      "train loss 0.281\n",
      "train loss 0.291\n",
      "train loss 0.272\n",
      "train loss 0.271\n",
      "train loss 0.268\n",
      "train loss 0.263\n",
      "train loss 0.260\n",
      "train loss 0.257\n",
      "train loss 0.252\n",
      "train loss 0.246\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "model_mf_nn = MF_nn(user_max, item_max, emb_size=50) \n",
    "training_mf_nn(model_mf_nn, df, epochs=35, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4c5a7af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:01.455158Z",
     "start_time": "2022-02-15T03:43:00.919666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47756058\n",
      "[0.47095193]\n"
     ]
    }
   ],
   "source": [
    "users = torch.LongTensor(test['user_id'].values)\n",
    "items = torch.LongTensor(test['item_id'].values)\n",
    "\n",
    "y_pred = model_mf_nn(users, items).detach().numpy()\n",
    "test['rating']= y_pred\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7eede38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:02.075019Z",
     "start_time": "2022-02-15T03:43:01.455999Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"predict_nn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3f6b6",
   "metadata": {},
   "source": [
    "## Random Forest with extracted trained embedding, and two features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ff53a",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2aae391f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:02.080896Z",
     "start_time": "2022-02-15T03:43:02.075879Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_df, optimizer, feature_flag=False):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    users = torch.LongTensor(train_df['user'].values)  #.cuda()\n",
    "    items = torch.LongTensor(train_df['item'].values) #.cuda()\n",
    "    ratings = torch.FloatTensor(train_df['rating'].values)  #.cuda()\n",
    "\n",
    "    if feature_flag == True:\n",
    "        item_feature = torch.LongTensor(train_df['item_feature'].values) #.cuda()\n",
    "        context_feature = torch.LongTensor(train_df['context_feature'].values) #.cuda()\n",
    "        y_hat = model(users, items, item_feature, context_feature)\n",
    "    else:\n",
    "        y_hat = model(users, items)\n",
    "    loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    ### END SOLUTION\n",
    "    return train_loss\n",
    "\n",
    "def training(model, train_df, epochs=10, lr=0.01, wd=0.0, feature_flag=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch(model, train_df, optimizer, feature_flag)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c4c9842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:16.247317Z",
     "start_time": "2022-02-15T03:43:02.082005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.694\n",
      "train loss 0.657\n",
      "train loss 0.593\n",
      "train loss 0.552\n",
      "train loss 0.515\n",
      "train loss 0.475\n",
      "train loss 0.435\n",
      "train loss 0.396\n",
      "train loss 0.361\n",
      "train loss 0.330\n",
      "train loss 0.306\n",
      "train loss 0.290\n",
      "train loss 0.279\n",
      "train loss 0.272\n",
      "train loss 0.268\n",
      "train loss 0.266\n",
      "train loss 0.265\n",
      "train loss 0.263\n",
      "train loss 0.259\n",
      "train loss 0.253\n",
      "train loss 0.246\n",
      "train loss 0.239\n",
      "train loss 0.232\n",
      "train loss 0.226\n",
      "train loss 0.221\n",
      "train loss 0.217\n",
      "train loss 0.213\n",
      "train loss 0.210\n",
      "train loss 0.207\n",
      "train loss 0.204\n",
      "train loss 0.200\n",
      "train loss 0.197\n",
      "train loss 0.194\n",
      "train loss 0.191\n",
      "train loss 0.189\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "model = MF(user_max, item_max, emb_size=10) \n",
    "training(model, df, epochs=35, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcd6a5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:16.420211Z",
     "start_time": "2022-02-15T03:43:16.248122Z"
    }
   },
   "outputs": [],
   "source": [
    "item_embeddings = model.item_emb.weight.detach().numpy()\n",
    "user_embeddings = model.user_emb.weight.detach().numpy()\n",
    "train_user_embeddings = pd.DataFrame(user_embeddings[df['user'].values], \n",
    "                                     columns= [f'ue_{i}' for i in range(user_embeddings.shape[1])])\n",
    "train_item_embeddings = pd.DataFrame(item_embeddings[df['item'].values], \n",
    "                                     columns= [f'ie_{i}' for i in range(user_embeddings.shape[1])])\n",
    "train = pd.concat((df['context_feature'], df['item_feature'],\n",
    "                   train_user_embeddings, train_item_embeddings), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e090743d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:43:16.427499Z",
     "start_time": "2022-02-15T03:43:16.421086Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context_feature</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_feature</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_0</th>\n",
       "      <td>0.301027</td>\n",
       "      <td>0.301027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_1</th>\n",
       "      <td>-0.247001</td>\n",
       "      <td>-0.247001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_2</th>\n",
       "      <td>-0.066983</td>\n",
       "      <td>-0.066983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_3</th>\n",
       "      <td>-0.580410</td>\n",
       "      <td>-0.580410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_4</th>\n",
       "      <td>-0.605586</td>\n",
       "      <td>-0.605586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_5</th>\n",
       "      <td>-0.441356</td>\n",
       "      <td>-0.441356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_6</th>\n",
       "      <td>-0.335058</td>\n",
       "      <td>-0.335058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_7</th>\n",
       "      <td>-0.422628</td>\n",
       "      <td>-0.422628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_8</th>\n",
       "      <td>0.119765</td>\n",
       "      <td>0.119765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ue_9</th>\n",
       "      <td>0.037175</td>\n",
       "      <td>0.037175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_0</th>\n",
       "      <td>0.553410</td>\n",
       "      <td>0.118406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_1</th>\n",
       "      <td>-0.127302</td>\n",
       "      <td>-0.053249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_2</th>\n",
       "      <td>-0.648921</td>\n",
       "      <td>-0.012833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_3</th>\n",
       "      <td>-0.516288</td>\n",
       "      <td>-0.022850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_4</th>\n",
       "      <td>-0.954960</td>\n",
       "      <td>0.303412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_5</th>\n",
       "      <td>-0.833033</td>\n",
       "      <td>0.553118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_6</th>\n",
       "      <td>-0.981144</td>\n",
       "      <td>-0.243373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_7</th>\n",
       "      <td>-0.751958</td>\n",
       "      <td>-0.010951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_8</th>\n",
       "      <td>0.182734</td>\n",
       "      <td>0.123337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie_9</th>\n",
       "      <td>0.798073</td>\n",
       "      <td>-0.229702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1\n",
       "context_feature  2.000000  2.000000\n",
       "item_feature     7.000000  7.000000\n",
       "ue_0             0.301027  0.301027\n",
       "ue_1            -0.247001 -0.247001\n",
       "ue_2            -0.066983 -0.066983\n",
       "ue_3            -0.580410 -0.580410\n",
       "ue_4            -0.605586 -0.605586\n",
       "ue_5            -0.441356 -0.441356\n",
       "ue_6            -0.335058 -0.335058\n",
       "ue_7            -0.422628 -0.422628\n",
       "ue_8             0.119765  0.119765\n",
       "ue_9             0.037175  0.037175\n",
       "ie_0             0.553410  0.118406\n",
       "ie_1            -0.127302 -0.053249\n",
       "ie_2            -0.648921 -0.012833\n",
       "ie_3            -0.516288 -0.022850\n",
       "ie_4            -0.954960  0.303412\n",
       "ie_5            -0.833033  0.553118\n",
       "ie_6            -0.981144 -0.243373\n",
       "ie_7            -0.751958 -0.010951\n",
       "ie_8             0.182734  0.123337\n",
       "ie_9             0.798073 -0.229702"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69883a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:49:43.322981Z",
     "start_time": "2022-02-15T03:43:16.428364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.fit(train, df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d015b6",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdfd6bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:49:43.377209Z",
     "start_time": "2022-02-15T03:49:43.324428Z"
    }
   },
   "outputs": [],
   "source": [
    "test_user_embeddings = pd.DataFrame(user_embeddings[test['user_id'].values], \n",
    "                                    columns= [f'ue_{i}' for i in range(user_embeddings.shape[1])])\n",
    "test_item_embeddings = pd.DataFrame(item_embeddings[test['item_id'].values], \n",
    "                                    columns= [f'ie_{i}' for i in range(user_embeddings.shape[1])])\n",
    "test_df = pd.concat((test['context_feature_id'], test['item_feature'], \n",
    "                     test_user_embeddings, test_item_embeddings), axis=1)\n",
    "test_df.rename(columns={\"context_feature_id\": \"context_feature\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe81abc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:49:45.968943Z",
     "start_time": "2022-02-15T03:49:43.378309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4060962020006031\n",
      "0.4060962020006031\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(test_df)\n",
    "test['rating']= y_pred\n",
    "\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c47e5dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T03:49:46.283927Z",
     "start_time": "2022-02-15T03:49:45.969741Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"predict_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3be449",
   "metadata": {},
   "source": [
    "## Neural Network with Extra Features (Data Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4223ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class NNDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user = df['user'].values\n",
    "        self.item = df['item'].values\n",
    "        self.item_feature = df['item_feature'].values\n",
    "        self.context_feature = df['context_feature'].values\n",
    "        self.rating = df['rating'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.user)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user[index]\n",
    "        item_id = self.item[index]\n",
    "        item_feature = self.item_feature[index]\n",
    "        context_feature = self.context_feature[index]\n",
    "        rating = self.rating[index]\n",
    "        return {\"user_id\": user_id,\n",
    "                \"item_id\": item_id, \n",
    "                \"item_feature\": item_feature,\n",
    "                \"context_feature\": context_feature,\n",
    "                \"rating\": rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a3eece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = NNDataset(df)\n",
    "data_dl = DataLoader(data_ds, batch_size=50000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f34595a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_item_features, n_context_features, \n",
    "                layers=[200, 100],\n",
    "                dropout=0.8):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dim = int(layers[0] * 3/8)\n",
    "        self.item_feature_embedding_dim = int(layers[0] * 1/5)\n",
    "        self.context_feature_embedding_dim = int(layers[0] * 1/20)\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(n_users+1, self.embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items+1, self.embedding_dim)\n",
    "        self.item_feature_embedding = nn.Embedding(n_item_features+1, self.item_feature_embedding_dim)\n",
    "        self.context_feature_embedding = nn.Embedding(n_context_features+1, self.context_feature_embedding_dim)        \n",
    "\n",
    "        # init \n",
    "        self.user_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.item_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.item_feature_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.context_feature_embedding.weight.data.uniform_(0,0.05)        \n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        for _, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        # final prediction layer\n",
    "        self.output_layer = torch.nn.Linear(layers[-1], 1)\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        users = feed_dict['user_id']\n",
    "        items = feed_dict['item_id']\n",
    "        item_features = feed_dict['item_feature']\n",
    "        context_features = feed_dict['context_feature']\n",
    "\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        item_embedding = self.item_embedding(items)\n",
    "        item_feature_embedding = self.item_feature_embedding(item_features)\n",
    "        context_feature_embedding = self.context_feature_embedding(context_features)    \n",
    "\n",
    "        # concatenate user and item embeddings to form input\n",
    "        x = torch.cat([user_embedding, item_embedding, \n",
    "                       item_feature_embedding, context_feature_embedding], 1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,  p=self.dropout, training=self.training)\n",
    "        logit = self.output_layer(x)\n",
    "        out = torch.sigmoid(logit)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "872b75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metric(model, data_loader):\n",
    "    losses = []\n",
    "    y_hats = []\n",
    "    ys = []\n",
    "    model.eval()\n",
    "    for feed_dict in data_loader:\n",
    "        prediction = model(feed_dict)\n",
    "        rating = feed_dict['rating'] \n",
    "        rating = rating.float().view(prediction.size()) \n",
    "        loss = F.binary_cross_entropy(prediction, rating)\n",
    "        y_hats.append(prediction.detach().numpy())\n",
    "        ys.append(rating.numpy())\n",
    "        losses.append(loss.item())\n",
    "    ys = np.concatenate(ys)\n",
    "    y_hats = np.concatenate(y_hats)\n",
    "    ypred_hard = np.where(y_hats > 0.5, 1, 0)\n",
    "    valid_acc = np.sum(ys == ypred_hard) / len(ys)    \n",
    "    return np.mean(losses), valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "107b3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for feed_dict in data_loader:\n",
    "        prediction = model(feed_dict)\n",
    "        rating = feed_dict['rating']        \n",
    "        # convert to float and change dim from [batch_size] to [batch_size,1]\n",
    "        rating = rating.float().view(prediction.size())  \n",
    "        loss = F.binary_cross_entropy(prediction, rating)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64a77012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, train_dl, epochs=10, lr=0.01, wd=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch(model, train_dl, optimizer)\n",
    "        # valid_loss, valid_acc = val_metric(model, valid_dl)\n",
    "        print(f\"train loss {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "61cd607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "context_feature_max = df['context_feature'].max()\n",
    "item_feature_max = df['item_feature'].max()\n",
    "mlp = MLP(user_max, item_max, item_feature_max, context_feature_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00eeddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.443\n",
      "train loss 0.372\n",
      "train loss 0.358\n",
      "train loss 0.347\n",
      "train loss 0.340\n",
      "train loss 0.334\n",
      "train loss 0.331\n",
      "train loss 0.328\n",
      "train loss 0.328\n",
      "train loss 0.327\n"
     ]
    }
   ],
   "source": [
    "train_nn(mlp, data_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bd65d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.309\n"
     ]
    }
   ],
   "source": [
    "train_nn(mlp, data_dl, epochs=1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64f6b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean embedding for the unknown users\n",
    "with torch.no_grad():\n",
    "    user_unique = df['user'].unique()\n",
    "    user_n = len(user_unique)\n",
    "    sum_embeddings = torch.zeros(mlp.user_embedding.weight.shape[1])\n",
    "    for user in user_unique:\n",
    "        sum_embeddings += mlp.user_embedding.weight[user]\n",
    "    mlp.user_embedding.weight[user_max] = sum_embeddings / user_n\n",
    "\n",
    "with torch.no_grad():\n",
    "    item_unique = df['item'].unique()\n",
    "    item_n = len(item_unique)\n",
    "    sum_embeddings = torch.zeros(mlp.item_embedding.weight.shape[1])\n",
    "    for item in item_unique:\n",
    "        sum_embeddings += mlp.item_embedding.weight[item]\n",
    "    mlp.item_embedding.weight[item_max] = sum_embeddings / item_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "15ca98e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49968666\n",
      "[0.49246824]\n"
     ]
    }
   ],
   "source": [
    "test_mod = test.copy()\n",
    "test_mod.loc[~test_mod['user_id'].isin(df['user']), 'user_id'] = user_max\n",
    "test_mod.loc[~test_mod['item_id'].isin(df['item']), 'item_id'] = item_max\n",
    "\n",
    "users = torch.LongTensor(test_mod['user_id'].values)\n",
    "items = torch.LongTensor(test_mod['item_id'].values)\n",
    "item_features = torch.LongTensor(test_mod['item_feature'].values)\n",
    "context_features = torch.LongTensor(test_mod['context_feature_id'].values)\n",
    "\n",
    "test_input = {\n",
    "    \"user_id\": users,\n",
    "    \"item_id\": items,\n",
    "    \"item_feature\": item_features,\n",
    "    \"context_feature\": context_features,\n",
    "}\n",
    "\n",
    "mlp.eval()\n",
    "y_pred = mlp(test_input).detach().numpy()\n",
    "test['rating']= y_pred\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2d215d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"DL_Master_Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab58cb0",
   "metadata": {},
   "source": [
    "## Another Neural Network with Extra Features (TensorDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "964ab542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split x and y and put into tersor dataset, and dataloader\n",
    "user_tensor = torch.LongTensor(df['user'].values)\n",
    "item_tensor = torch.LongTensor(df['item'].values)\n",
    "context_feature_tensor = torch.LongTensor(df['context_feature'].values)\n",
    "item_feature_tensor = torch.LongTensor(df['item_feature'].values)\n",
    "rating_tensor = torch.FloatTensor(df['rating'].values)\n",
    "\n",
    "train_data = TensorDataset(user_tensor, item_tensor, context_feature_tensor,\n",
    "                          item_feature_tensor, rating_tensor)\n",
    "train_dl = DataLoader(train_data, batch_size=500000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4d1f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(train_dl)\n",
    "first = next(dataset_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd26477b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 15730,  52897, 124460,  ...,  13427, 173838, 106574]),\n",
       " tensor([10984,  6366, 22793,  ..., 15479, 30550, 11530]),\n",
       " tensor([1, 1, 1,  ..., 2, 2, 3]),\n",
       " tensor([174,  55, 148,  ..., 139,  68, 153]),\n",
       " tensor([0., 0., 1.,  ..., 0., 1., 0.])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5b38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_nn(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_context_feature, \n",
    "                 num_item_feature, emb_size=40, \n",
    "                 emb_size_context_feature=5, emb_size_item_feature=10, seed=23):\n",
    "        super(MF_nn, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.user_emb = nn.Embedding(num_users+1, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users+1, 1)\n",
    "        self.item_emb = nn.Embedding(num_items+1, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items+1, 1)\n",
    "        \n",
    "        self.context_feature_emb = nn.Embedding(num_context_feature+1, emb_size_context_feature)\n",
    "        self.context_feature_bias = nn.Embedding(num_context_feature+1, 1)\n",
    "        self.item_feature_emb = nn.Embedding(num_item_feature+1, emb_size_item_feature)\n",
    "        self.item_feature_bias = nn.Embedding(num_item_feature+1, 1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(95, 50)\n",
    "        self.linear2 = nn.Linear(50, 25)\n",
    "        self.linear3 = nn.Linear(25, 1)\n",
    "        \n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.context_feature_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_feature_emb.weight.data.uniform_(0,0.05)        \n",
    "\n",
    "    def forward(self, u, v, cf, vf):\n",
    "        ### BEGIN SOLUTION\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        CF = self.context_feature_emb(cf)\n",
    "        VF = self.item_feature_emb(vf)\n",
    "        \n",
    "        x = torch.cat([U, V, CF, VF], 1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.6)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.6)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5755935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_mf_nn(model, train_dl, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    epoch_loss = []\n",
    "    model.to(device)\n",
    "#    if n_gpu > 1:\n",
    "#        model = torch.nn.DataParallel(model)\n",
    "    model.train()\n",
    "    ### BEGIN SOLUTION\n",
    "    for batch in tqdm(train_dl):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        users, items, context_features, item_feature, ratings = batch\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "\n",
    "        y_hat = model(users, items, context_features, item_feature)\n",
    "        loss = F.binary_cross_entropy(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step_loss = loss.item()\n",
    "        epoch_loss.append(step_loss)\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    ### END SOLUTION\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53a060dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_mf_nn(model, train_dl, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_one_epoch_mf_nn(model, train_dl, optimizer)\n",
    "        print(\"train loss %.3f\" % (train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e4f2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(item_feature, left_on='item_id', right_on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a223975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:20<00:00, 13.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:22<00:00, 13.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:21<00:00, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:20<00:00, 13.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:20<00:00, 13.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:22<00:00, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "context_feature_max = df['context_feature'].max()\n",
    "item_feature_max = df['item_feature'].max()\n",
    "\n",
    "model_mf_nn = MF_nn(user_max, item_max, \n",
    "                    context_feature_max, item_feature_max) \n",
    "training_mf_nn(model_mf_nn, train_dl, epochs=6, lr=0.01, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f386dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [01:21<00:00, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_mf_nn(model_mf_nn, train_dl, epochs=1, lr=0.001, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35d99101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49340406\n",
      "[0.52819067]\n"
     ]
    }
   ],
   "source": [
    "users = torch.LongTensor(test['user_id'].values).to(device)\n",
    "items = torch.LongTensor(test['item_id'].values).to(device)\n",
    "context_features = torch.LongTensor(test['context_feature_id'].values).to(device)\n",
    "item_features = torch.LongTensor(test['item_feature_id'].values).to(device)\n",
    "\n",
    "y_pred = model_mf_nn(users, items, context_features, item_features).detach().cpu().numpy()\n",
    "test['rating']= y_pred\n",
    "\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fce4b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"predict_nn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929373c7",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27885e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_item_features, n_context_features, \n",
    "                layers=[280, 100],\n",
    "                dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dim = int(layers[0] * 3/8)\n",
    "        self.item_feature_embedding_dim = int(layers[0] * 1/5)\n",
    "        self.context_feature_embedding_dim = int(layers[0] * 1/20)\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(n_users+1, self.embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items+1, self.embedding_dim)\n",
    "        self.item_feature_embedding = nn.Embedding(n_item_features+1, self.item_feature_embedding_dim)\n",
    "        self.context_feature_embedding = nn.Embedding(n_context_features+1, self.context_feature_embedding_dim)        \n",
    "\n",
    "        # init \n",
    "        self.user_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.item_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.item_feature_embedding.weight.data.uniform_(0,0.05)\n",
    "        self.context_feature_embedding.weight.data.uniform_(0,0.05)        \n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        for _, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        # final prediction layer\n",
    "        self.output_layer = torch.nn.Linear(layers[-1], 1)\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        users = feed_dict['user_id']\n",
    "        items = feed_dict['item_id']\n",
    "        item_features = feed_dict['item_feature']\n",
    "        context_features = feed_dict['context_feature']\n",
    "\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        item_embedding = self.item_embedding(items)\n",
    "        item_feature_embedding = self.item_feature_embedding(item_features)\n",
    "        context_feature_embedding = self.context_feature_embedding(context_features)    \n",
    "\n",
    "        # concatenate user and item embeddings to form input\n",
    "        x = torch.cat([user_embedding, item_embedding, \n",
    "                       item_feature_embedding, context_feature_embedding], 1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,  p=self.dropout, training=self.training)\n",
    "        logit = self.output_layer(x)\n",
    "        out = torch.sigmoid(logit)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3914bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_max = df['item'].max()\n",
    "user_max = df['user'].max()\n",
    "context_feature_max = df['context_feature'].max()\n",
    "item_feature_max = df['item_feature'].max()\n",
    "mlp = MLP(user_max, item_max, item_feature_max, context_feature_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cb4f352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.403\n",
      "train loss 0.334\n",
      "train loss 0.320\n",
      "train loss 0.315\n",
      "train loss 0.314\n",
      "train loss 0.313\n",
      "train loss 0.312\n",
      "train loss 0.311\n",
      "train loss 0.310\n",
      "train loss 0.310\n"
     ]
    }
   ],
   "source": [
    "train_nn(mlp, data_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28c755c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.310\n",
      "train loss 0.306\n",
      "train loss 0.306\n",
      "train loss 0.306\n",
      "train loss 0.306\n"
     ]
    }
   ],
   "source": [
    "# Train for another 5 epochs\n",
    "train_nn(mlp, data_dl, epochs=5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd731c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.299\n",
      "train loss 0.295\n",
      "train loss 0.294\n",
      "train loss 0.294\n",
      "train loss 0.294\n"
     ]
    }
   ],
   "source": [
    "# Train with lower learning rate\n",
    "train_nn(mlp, data_dl, epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b781dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.292\n",
      "train loss 0.291\n",
      "train loss 0.291\n",
      "train loss 0.291\n",
      "train loss 0.291\n"
     ]
    }
   ],
   "source": [
    "# Train with even lower learning rate\n",
    "train_nn(mlp, data_dl, epochs=5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b77655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean embedding for the unknown users\n",
    "with torch.no_grad():\n",
    "    user_unique = df['user'].unique()\n",
    "    user_n = len(user_unique)\n",
    "    sum_embeddings = torch.zeros(mlp.user_embedding.weight.shape[1])\n",
    "    for user in user_unique:\n",
    "        sum_embeddings += mlp.user_embedding.weight[user]\n",
    "    mlp.user_embedding.weight[user_max] = sum_embeddings / user_n\n",
    "\n",
    "with torch.no_grad():\n",
    "    item_unique = df['item'].unique()\n",
    "    item_n = len(item_unique)\n",
    "    sum_embeddings = torch.zeros(mlp.item_embedding.weight.shape[1])\n",
    "    for item in item_unique:\n",
    "        sum_embeddings += mlp.item_embedding.weight[item]\n",
    "    mlp.item_embedding.weight[item_max] = sum_embeddings / item_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fc814b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49312255\n",
      "[0.46982183]\n"
     ]
    }
   ],
   "source": [
    "test_mod = test.copy()\n",
    "test_mod.loc[~test_mod['user_id'].isin(df['user']), 'user_id'] = user_max\n",
    "test_mod.loc[~test_mod['item_id'].isin(df['item']), 'item_id'] = item_max\n",
    "\n",
    "users = torch.LongTensor(test_mod['user_id'].values)\n",
    "items = torch.LongTensor(test_mod['item_id'].values)\n",
    "item_features = torch.LongTensor(test_mod['item_feature'].values)\n",
    "context_features = torch.LongTensor(test_mod['context_feature_id'].values)\n",
    "\n",
    "test_input = {\n",
    "    \"user_id\": users,\n",
    "    \"item_id\": items,\n",
    "    \"item_feature\": item_features,\n",
    "    \"context_feature\": context_features,\n",
    "}\n",
    "\n",
    "mlp.eval()\n",
    "y_pred = mlp(test_input).detach().numpy()\n",
    "test['rating']= y_pred\n",
    "print(np.mean(y_pred))\n",
    "ypred_hard= np.where(y_pred >= 0.5, 1, 0)\n",
    "print(sum(ypred_hard == 1) / len(ypred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bb98af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'rating']].to_csv(\"DL_Master_Submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
